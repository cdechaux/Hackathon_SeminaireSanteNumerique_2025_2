==========================================
SLURM_JOB_ID = 4273183
SLURM_JOB_NODELIST = gpu016
==========================================
Requirement already satisfied: numpy<3.0,>=1.26 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.6)
Requirement already satisfied: pandas<3.0,>=2.2 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.3.2)
Collecting scikit-learn<1.6,>=1.4 (from -r requirements.txt (line 4))
  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)
Requirement already satisfied: joblib<2.0,>=1.3 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.5.2)
Requirement already satisfied: tqdm<5.0,>=4.66 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.67.1)
Collecting torch<2.6,>=2.4 (from -r requirements.txt (line 9))
  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)
Requirement already satisfied: transformers<5.0,>=4.43 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (4.56.1)
Collecting accelerate<1.0,>=0.31 (from -r requirements.txt (line 11))
  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)
Requirement already satisfied: safetensors<1.0,>=0.4 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.6.2)
Collecting tokenizers<0.20,>=0.15 (from -r requirements.txt (line 13))
  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Requirement already satisfied: sentencepiece>=0.1.99 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.2.1)
Requirement already satisfied: datasets in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (4.0.0)
Collecting medkit-lib>=0.17.0 (from -r requirements.txt (line 18))
  Using cached medkit_lib-0.17.0-py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: python-dateutil>=2.8.2 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from pandas<3.0,>=2.2->-r requirements.txt (line 3)) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from pandas<3.0,>=2.2->-r requirements.txt (line 3)) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from pandas<3.0,>=2.2->-r requirements.txt (line 3)) (2025.2)
Requirement already satisfied: scipy>=1.6.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from scikit-learn<1.6,>=1.4->-r requirements.txt (line 4)) (1.15.3)
Requirement already satisfied: threadpoolctl>=3.1.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from scikit-learn<1.6,>=1.4->-r requirements.txt (line 4)) (3.6.0)
Requirement already satisfied: filelock in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from torch<2.6,>=2.4->-r requirements.txt (line 9)) (3.19.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from torch<2.6,>=2.4->-r requirements.txt (line 9)) (4.15.0)
Requirement already satisfied: networkx in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from torch<2.6,>=2.4->-r requirements.txt (line 9)) (3.4.2)
Requirement already satisfied: jinja2 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from torch<2.6,>=2.4->-r requirements.txt (line 9)) (3.1.6)
Requirement already satisfied: fsspec in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from torch<2.6,>=2.4->-r requirements.txt (line 9)) (2025.3.0)
Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-nccl-cu12==2.21.5 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvtx-cu12==12.4.127 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting triton==3.1.0 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)
Collecting sympy==1.13.1 (from torch<2.6,>=2.4->-r requirements.txt (line 9))
  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from sympy==1.13.1->torch<2.6,>=2.4->-r requirements.txt (line 9)) (1.3.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from transformers<5.0,>=4.43->-r requirements.txt (line 10)) (0.34.4)
Requirement already satisfied: packaging>=20.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from transformers<5.0,>=4.43->-r requirements.txt (line 10)) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from transformers<5.0,>=4.43->-r requirements.txt (line 10)) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from transformers<5.0,>=4.43->-r requirements.txt (line 10)) (2025.7.34)
Requirement already satisfied: requests in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from transformers<5.0,>=4.43->-r requirements.txt (line 10)) (2.32.5)
INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.
Collecting transformers<5.0,>=4.43 (from -r requirements.txt (line 10))
  Using cached transformers-4.56.2-py3-none-any.whl.metadata (40 kB)
  Using cached transformers-4.56.0-py3-none-any.whl.metadata (40 kB)
  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)
  Using cached transformers-4.55.3-py3-none-any.whl.metadata (41 kB)
  Using cached transformers-4.55.2-py3-none-any.whl.metadata (41 kB)
  Using cached transformers-4.55.1-py3-none-any.whl.metadata (41 kB)
  Using cached transformers-4.55.0-py3-none-any.whl.metadata (39 kB)
INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.
  Using cached transformers-4.54.1-py3-none-any.whl.metadata (41 kB)
  Using cached transformers-4.54.0-py3-none-any.whl.metadata (41 kB)
  Using cached transformers-4.53.3-py3-none-any.whl.metadata (40 kB)
  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)
  Using cached transformers-4.53.1-py3-none-any.whl.metadata (40 kB)
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Using cached transformers-4.53.0-py3-none-any.whl.metadata (39 kB)
  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)
  Using cached transformers-4.52.3-py3-none-any.whl.metadata (40 kB)
  Using cached transformers-4.52.2-py3-none-any.whl.metadata (40 kB)
  Using cached transformers-4.52.1-py3-none-any.whl.metadata (38 kB)
  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)
  Using cached transformers-4.51.2-py3-none-any.whl.metadata (38 kB)
  Using cached transformers-4.51.1-py3-none-any.whl.metadata (38 kB)
  Using cached transformers-4.51.0-py3-none-any.whl.metadata (38 kB)
  Using cached transformers-4.50.3-py3-none-any.whl.metadata (39 kB)
  Using cached transformers-4.50.2-py3-none-any.whl.metadata (39 kB)
  Using cached transformers-4.50.1-py3-none-any.whl.metadata (39 kB)
  Using cached transformers-4.50.0-py3-none-any.whl.metadata (39 kB)
  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.48.2-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.48.1-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.48.0-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)
  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.46.2-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.46.1-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.45.2-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.45.1-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.45.0-py3-none-any.whl.metadata (44 kB)
  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)
Requirement already satisfied: psutil in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from accelerate<1.0,>=0.31->-r requirements.txt (line 11)) (7.0.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0,>=4.43->-r requirements.txt (line 10)) (1.1.9)
Requirement already satisfied: pyarrow>=15.0.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 15)) (21.0.0)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 15)) (0.3.8)
Requirement already satisfied: xxhash in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 15)) (3.5.0)
Requirement already satisfied: multiprocess<0.70.17 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 15)) (0.70.16)
Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (3.12.15)
Collecting anyascii (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)
Collecting duptextfinder>=0.3.0 (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached duptextfinder-0.3.0-py3-none-any.whl.metadata (2.9 kB)
Collecting flashtext>=2.7 (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached flashtext-2.7.tar.gz (14 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting intervaltree (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached intervaltree-3.1.0.tar.gz (32 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting pyaml (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)
Collecting pysimstring (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Downloading pysimstring-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (931 bytes)
Collecting smart-open (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)
Collecting soundfile (from medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)
Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (2.6.1)
Requirement already satisfied: aiosignal>=1.4.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (1.4.0)
Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (5.0.1)
Requirement already satisfied: attrs>=17.3.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (25.3.0)
Requirement already satisfied: frozenlist>=1.1.1 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (1.7.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (6.6.4)
Requirement already satisfied: propcache>=0.2.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (0.3.2)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (1.20.1)
Requirement already satisfied: idna>=2.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 15)) (3.10)
Requirement already satisfied: six>=1.5 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=2.2->-r requirements.txt (line 3)) (1.17.0)
Requirement already satisfied: charset_normalizer<4,>=2 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from requests->transformers<5.0,>=4.43->-r requirements.txt (line 10)) (3.4.3)
Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from requests->transformers<5.0,>=4.43->-r requirements.txt (line 10)) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from requests->transformers<5.0,>=4.43->-r requirements.txt (line 10)) (2025.8.3)
Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: MarkupSafe>=2.0 in /home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages (from jinja2->torch<2.6,>=2.4->-r requirements.txt (line 9)) (3.0.2)
Collecting wrapt (from smart-open->medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Downloading wrapt-1.17.3-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)
Collecting cffi>=1.0 (from soundfile->medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)
Collecting pycparser (from cffi>=1.0->soundfile->medkit-lib>=0.17.0->-r requirements.txt (line 18))
  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)
Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 71.2 MB/s  0:00:00
Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 906.4/906.4 MB 39.9 MB/s  0:00:12
Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)
Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 MB 84.2 MB/s  0:00:02
Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)
Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)
Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 72.9 MB/s  0:00:00
Using cached medkit_lib-0.17.0-py3-none-any.whl (286 kB)
Using cached duptextfinder-0.3.0-py3-none-any.whl (17 kB)
Using cached anyascii-0.3.3-py3-none-any.whl (345 kB)
Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
Using cached pyaml-25.7.0-py3-none-any.whl (26 kB)
Downloading pysimstring-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 47.6 MB/s  0:00:00
Using cached smart_open-7.3.1-py3-none-any.whl (61 kB)
Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)
Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)
Downloading pycparser-2.23-py3-none-any.whl (118 kB)
Downloading wrapt-1.17.3-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (81 kB)
Building wheels for collected packages: flashtext, intervaltree
  DEPRECATION: Building 'flashtext' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flashtext'. Discussion can be found at https://github.com/pypa/pip/issues/6334
  Building wheel for flashtext (setup.py): started
  Building wheel for flashtext (setup.py): finished with status 'done'
  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9372 sha256=607b3e837ecc44ae36fbc3505d3b785d2d3e0384f91295c6dfd8fd7579711eca
  Stored in directory: /home/cdechaux/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd
  DEPRECATION: Building 'intervaltree' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'intervaltree'. Discussion can be found at https://github.com/pypa/pip/issues/6334
  Building wheel for intervaltree (setup.py): started
  Building wheel for intervaltree (setup.py): finished with status 'done'
  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26190 sha256=8154449edb8ba0a2b7735c43047cad5e9242b3bf6fa5167b3e8d26541b0c8cea
  Stored in directory: /home/cdechaux/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61
Successfully built flashtext intervaltree
Installing collected packages: sortedcontainers, pysimstring, flashtext, duptextfinder, wrapt, triton, sympy, pycparser, pyaml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, intervaltree, anyascii, smart-open, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, cffi, tokenizers, soundfile, nvidia-cusolver-cu12, transformers, torch, medkit-lib, accelerate
  Attempting uninstall: triton
    Found existing installation: triton 3.4.0
    Uninstalling triton-3.4.0:
      Successfully uninstalled triton-3.4.0
  Attempting uninstall: sympy
    Found existing installation: sympy 1.14.0
    Uninstalling sympy-1.14.0:
      Successfully uninstalled sympy-1.14.0
  Attempting uninstall: nvidia-nvtx-cu12
    Found existing installation: nvidia-nvtx-cu12 12.8.90
    Uninstalling nvidia-nvtx-cu12-12.8.90:
      Successfully uninstalled nvidia-nvtx-cu12-12.8.90
  Attempting uninstall: nvidia-nvjitlink-cu12
    Found existing installation: nvidia-nvjitlink-cu12 12.8.93
    Uninstalling nvidia-nvjitlink-cu12-12.8.93:
      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93
  Attempting uninstall: nvidia-nccl-cu12
    Found existing installation: nvidia-nccl-cu12 2.27.3
    Uninstalling nvidia-nccl-cu12-2.27.3:
      Successfully uninstalled nvidia-nccl-cu12-2.27.3
  Attempting uninstall: nvidia-curand-cu12
    Found existing installation: nvidia-curand-cu12 10.3.9.90
    Uninstalling nvidia-curand-cu12-10.3.9.90:
      Successfully uninstalled nvidia-curand-cu12-10.3.9.90
  Attempting uninstall: nvidia-cufft-cu12
    Found existing installation: nvidia-cufft-cu12 11.3.3.83
    Uninstalling nvidia-cufft-cu12-11.3.3.83:
      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83
  Attempting uninstall: nvidia-cuda-runtime-cu12
    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90
    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:
      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90
  Attempting uninstall: nvidia-cuda-nvrtc-cu12
    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93
    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:
      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93
  Attempting uninstall: nvidia-cuda-cupti-cu12
    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90
    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:
      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90
  Attempting uninstall: nvidia-cublas-cu12
    Found existing installation: nvidia-cublas-cu12 12.8.4.1
    Uninstalling nvidia-cublas-cu12-12.8.4.1:
      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 1.7.1
    Uninstalling scikit-learn-1.7.1:
      Successfully uninstalled scikit-learn-1.7.1
  Attempting uninstall: nvidia-cusparse-cu12
    Found existing installation: nvidia-cusparse-cu12 12.5.8.93
    Uninstalling nvidia-cusparse-cu12-12.5.8.93:
      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93
  Attempting uninstall: nvidia-cudnn-cu12
    Found existing installation: nvidia-cudnn-cu12 9.10.2.21
    Uninstalling nvidia-cudnn-cu12-9.10.2.21:
      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21
  Attempting uninstall: tokenizers
    Found existing installation: tokenizers 0.22.0
    Uninstalling tokenizers-0.22.0:
      Successfully uninstalled tokenizers-0.22.0
  Attempting uninstall: nvidia-cusolver-cu12
    Found existing installation: nvidia-cusolver-cu12 11.7.3.90
    Uninstalling nvidia-cusolver-cu12-11.7.3.90:
      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90
  Attempting uninstall: transformers
    Found existing installation: transformers 4.56.1
    Uninstalling transformers-4.56.1:
      Successfully uninstalled transformers-4.56.1
  Attempting uninstall: torch
    Found existing installation: torch 2.8.0
    Uninstalling torch-2.8.0:
      Successfully uninstalled torch-2.8.0
  Attempting uninstall: accelerate
    Found existing installation: accelerate 1.10.1
    Uninstalling accelerate-1.10.1:
      Successfully uninstalled accelerate-1.10.1

ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
torchaudio 2.8.0 requires torch==2.8.0, but you have torch 2.5.1 which is incompatible.
torchvision 0.23.0 requires torch==2.8.0, but you have torch 2.5.1 which is incompatible.
umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.
Successfully installed accelerate-0.34.2 anyascii-0.3.3 cffi-2.0.0 duptextfinder-0.3.0 flashtext-2.7 intervaltree-3.1.0 medkit-lib-0.17.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pyaml-25.7.0 pycparser-2.23 pysimstring-1.3.0 scikit-learn-1.5.2 smart-open-7.3.1 sortedcontainers-2.4.0 soundfile-0.13.1 sympy-1.13.1 tokenizers-0.19.1 torch-2.5.1 transformers-4.44.2 triton-3.1.0 wrapt-1.17.3
/home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.

0it [00:00, ?it/s]
0it [00:00, ?it/s]

Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 125.68it/s]

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Loading checkpoint shards:  33%|███▎      | 1/3 [01:32<03:04, 92.23s/it]
Loading checkpoint shards:  67%|██████▋   | 2/3 [02:57<01:27, 87.90s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [04:24<00:00, 87.65s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [04:24<00:00, 88.15s/it]
/home/cdechaux/miniconda3/envs/pt_env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
[OK] Documents: 1000 | DP prédits: 879 | sortie: data/pred.csv
